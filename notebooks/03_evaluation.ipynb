{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/hibadash/-Breast-Ultrasound-Classification-Using-Xception-CNN-BUSI-Dataset/blob/ModelTraining/notebooks/03_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 03 — Évaluation du modèle Xception\n",
        "Ce notebook Colab permet d'évaluer le modèle Xception entraîné sur le dataset BUSI.\n",
        "\n",
        "## Objectifs :\n",
        "\n",
        "- Charger le modèle sauvegardé (model_xception_best.h5 ou model_xception_final.h5).\n",
        "- Calculer les métriques principales : accuracy, F1-score (macro, weighted), ROC-AUC.\n",
        "- Générer les visualisations : matrices de confusion (brute/normalisée) et courbes ROC multi-classes.\n",
        "- Exporter un rapport de classification et un résumé JSON des métriques.\n",
        "## Prérequis :\n",
        "\n",
        "Avoir exécuté le notebook d'entraînement et téléchargé les fichiers .h5.\n",
        "Déposer le modèle choisi dans le dossier results/ du projet avant de lancer la cellule d'évaluation (ou monter Google Drive et y accéder)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Préparation de l'environnement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YloqFpvz172a",
        "outputId": "2415a406-9d94-4dea-b4d9-36063a60a55a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'breast_project'...\n",
            "remote: Enumerating objects: 1640, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 1640 (delta 26), reused 14 (delta 1), pack-reused 1584 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1640/1640), 194.53 MiB | 21.27 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "Updating files: 100% (1589/1589), done.\n",
            "/content/breast_project\n",
            "app  data  notebooks  README.md  requirements.txt  results  src\n"
          ]
        }
      ],
      "source": [
        "# Étape 0.1 — Nettoyage éventuel de l'environnement Colab (optionnel)\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if os.path.exists(\"breast_project\"):\n",
        "    shutil.rmtree(\"breast_project\")\n",
        "    print(\"Répertoire 'breast_project' supprimé pour repartir proprement.\")\n",
        "else:\n",
        "    print(\"Aucun répertoire 'breast_project' à supprimer.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Étape 0.2 — Clonage du dépôt et positionnement dans le dossier racine\n",
        "!git clone --branch ModelTraining --single-branch https://github.com/hibadash/-Breast-Ultrasound-Classification-Using-Xception-CNN-BUSI-Dataset.git breast_project\n",
        "\n",
        "import os\n",
        "os.chdir(\"breast_project\")\n",
        "print(\"Répertoire courant :\", os.getcwd())\n",
        "print(\"Contenu du projet :\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Étape 0.3 — (Optionnel) Installation des dépendances supplémentaires\n",
        "# Cette cellule est utile si la VM Colab est vierge.\n",
        "!pip install -q tensorflow==2.15 seaborn scikit-learn matplotlib numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports et configuration globale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Étape 1 — Imports et configuration\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import runpy\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "PROJECT_ROOT = os.getcwd()\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.append(PROJECT_ROOT)\n",
        "\n",
        "from data.preprocess import test_generator\n",
        "\n",
        "try:\n",
        "    from src.evaluate import evaluate_model\n",
        "except (ImportError, AttributeError) as exc:\n",
        "    evaluate_globals = runpy.run_path(os.path.join(PROJECT_ROOT, \"src\", \"evaluate.py\"))\n",
        "    evaluate_model = evaluate_globals.get(\"evaluate_model\")\n",
        "    if evaluate_model is None:\n",
        "        raise ImportError(\"Impossible de charger evaluate_model depuis src/evaluate.py\") from exc\n",
        "    print(\"[INFO] evaluate_model importé via runpy (fallback). Détail de l'exception initiale:\", exc)\n",
        "\n",
        "RESULTS_DIR = \"results\"\n",
        "MODEL_PATH = os.path.join(RESULTS_DIR, \"model_xception_best.h5\")  # Modifiez si nécessaire\n",
        "RUN_NAME = \"test_split\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Étape 1.1 — Vérifications préliminaires\n",
        "print(\"Fichier modèle attendu :\", MODEL_PATH)\n",
        "print(\"Répertoire des résultats :\", os.path.abspath(RESULTS_DIR))\n",
        "print(\"Répertoire courant :\", os.getcwd())\n",
        "print(\"Test generator classes :\", test_generator.class_indices)\n",
        "print(\"Nombre d'images de test :\", test_generator.samples)\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Le fichier {MODEL_PATH} est introuvable. Vérifiez le chemin ou téléversez le modèle.\"\n",
        "    )\n",
        "else:\n",
        "    print(\"Modèle trouvé, prêt pour l'évaluation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Évaluation du modèle sur le jeu de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Étape 2 — Évaluation du modèle\n",
        "results = evaluate_model(\n",
        "    model_path=MODEL_PATH,\n",
        "    data_generator=test_generator,\n",
        "    results_dir=RESULTS_DIR,\n",
        "    run_name=RUN_NAME,\n",
        ")\n",
        "\n",
        "print(\"Métriques globales :\")\n",
        "print(json.dumps(results[\"metrics\"], indent=2))\n",
        "\n",
        "print(\"\\nClassification report :\")\n",
        "print(results[\"classification_report\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Visualisation des artefacts générés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Étape 3 — Affichage des visualisations enregistrées\n",
        "image_paths = [\n",
        "    (\"Matrice de confusion\", results[\"confusion_matrix_path\"]),\n",
        "    (\"Matrice de confusion normalisée\", results[\"confusion_matrix_normalized_path\"]),\n",
        "    (\"Courbes ROC\", results[\"roc_curves_path\"]),\n",
        "]\n",
        "\n",
        "for title, path in image_paths:\n",
        "    if os.path.exists(path):\n",
        "        display(Image(filename=path))\n",
        "    else:\n",
        "        print(f\"Impossible de trouver '{path}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Téléchargement des artefacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Étape 4 — Téléchargement des fichiers générés\n",
        "artefacts = [\n",
        "    results[\"confusion_matrix_path\"],\n",
        "    results[\"confusion_matrix_normalized_path\"],\n",
        "    results[\"roc_curves_path\"],\n",
        "    results[\"classification_report_path\"],\n",
        "    results[\"metrics_path\"],\n",
        "]\n",
        "\n",
        "for artefact in artefacts:\n",
        "    if os.path.exists(artefact):\n",
        "        files.download(artefact)\n",
        "    else:\n",
        "        print(f\"Fichier introuvable : {artefact}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOeMDmOYVJ2gP0c7cahsV+R",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
